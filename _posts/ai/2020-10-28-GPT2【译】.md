---
title: "GPT2【译】"
categories:
    - AI
tags:
  - NLP
---

论文：Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever. [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)

自然语言处理任务（例如问题答案，机器翻译，阅读理解和摘要）通常通过在任务特定的数据集上进行监督学习来实现。我们证明，当在称为WebText的数百万个网页的新数据集上进行训练时，语言模型将开始学习这些任务而无需任何明确的监督。当以文档加问题为条件时，由语言模型生成的答案在CoQA数据集上达到55 F1-匹配或超过了4个基准系统中3个的性能，而无需使用127,000+个训练示例。语言模型的功能对于零镜头任务传输的成功至关重要，而增加它可以跨任务以对数线性方式提高性能。我们最大的模型GPT-2是一个1.5B参数的Transformer，它可以在零镜头设置下在8个经过测试的语言建模数据集中的7个上获得7个最新状态的结果，但仍不适合WebText。该模型的样本反映了这些改进，并包含了相关的文本段落。这些发现为建立语言处理系统提供了一条有希望的途径，该系统可以从自然发生的演示中学习执行任务

如今，机器学习系统通过结合使用大型数据集，高容量模型和监督学习在训练任务上表现出众（预期）（Krizhevsky等人，2012）（Sutskever等人，2014）（Amodei等人） 等人，2016年）。 然而，这些系统非常脆弱，并且对数据分布（Recht等人，2018）和任务规范（Kirkpatrick等人，2017）的细微变化敏感。 当前系统最好被描述为狭窄的专家而不是专家有能力的通才。 我们希望转向可以执行许多任务的更通用的系统-最终无需手动为每个系统创建和标记训练数据集


创建ML系统的主要方法是收集一个训练示例数据集，以证明所需任务的正确行为，训练一个系统来模仿这些行为，然后在独立且均布的（IID）支持示例上测试其性能。 。这对于在狭窄的专家上取得进展起到了很好的作用。但是字幕模型（Lake等，2017），阅读理解系统（Jia＆Liang，2017）和图像分类器（Alcorn等，2018）经常会表现出不稳定的行为，突出说明了可能的输入的多样性和多样性。这种方法的缺点。我们的怀疑是，对单域数据集进行单任务训练的普遍性是造成当前系统缺乏普遍性的主要原因。在使用当前体系结构的健壮系统上取得进展可能需要对各种领域和任务进行培训和衡量性能。最近，已经提出了一些基准测试，例如GLUE（Wang等人，2018）和decaNLP（McCann等人，2018）以开始研究此基准。

多任务学习（Caruana，1997）是提高综合绩效的有前途的框架。但是，NLP中的多任务培训仍处于初期。最近的工作报告了适度的性能改进（Yogatama等，2019），以及迄今为止两项最雄心勃勃的工作，分别对总共10对和17对（数据集，目标）进行了培训（McCann等，2018）（Bowman等人，2018）。从元学习的角度来看，每对（数据集，目标）都是从数据集和目标分布中采样的单个训练示例。当前的ML系统需要成百上千个示例来诱发泛化得很好的功能。这表明，多任务训练中许多人都需要使用同样有效的训练对来实现其对当前方法的承诺。继续扩大数据集的创建和目标的设计，以达到用当前的技术强行破解我们的方式可能需要的程度，将是非常困难的。这激发了探索用于执行多任务学习的其他设置

当前在语言任务方面表现最佳的系统利用预训练和监督微调的组合。 这种方法由来已久，并且有朝着更灵活的转移形式发展的趋势。 首先，学习单词向量并将其用作特定任务架构的输入（Mikolov等，2013）（Collobert等，2011），然后转移递归网络的上下文表示（Dai＆Le，2015）。 （Peters等人，2018），最近的工作表明不再需要特定于任务的架构，并且转移许多自我注意力块就足够了（Radford等人，2018）（Devlin等人，2018）

这些方法仍然需要监督培训才能执行任务。 当只有很少或没有监督数据时，另一项工作证明了语言模型有望执行特定任务的希望，例如常识推理（Schwartz等，2017）和情感分析（Radford等，2017）。

我们方法的核心是语言建模。 语言建模通常被构造为一组示例（x1，x2，...，xn）的无监督分布估计，每个示例均由可变长度的符号序列（s1，s2，...，sn）组成。 由于语言具有自然的顺序顺序，因此通常将联合概率分解为符号作为条件概率的乘积（Jelinek＆Mercer，1980）（Bengio et al。，2003）

这种方法允许对p（x）以及p（snk，...，sn | s1，...，sn-k-1）形式的任何条件进行可采样的采样和估计。 近年来，可以计算这些条件概率的mod-el的表达能力有了重大改进，例如Transformer之类的自注意架构（Vaswani等，2017

学习执行单个任务可以在概率框架中表示为估计条件分布p（输入）。由于通用系统即使对于相同的输入也应该能够执行许多不同的任务，因此它不仅应以输入为条件，还应以要执行的任务为条件。即，应该对p（输出，任务）进行建模。在多任务和元学习设置中，这已经进行了各种形式化的定义。任务调节通常在体系结构级别（例如Kaiser等人，2017）中的特定于任务的编码器和解码器或在MAML的内外循环优化框架（Finn等人，2017）等算法级别上实现）。但正如McCann等人所举例说明的。 （2018），语言提供了一种灵活的方式来将任务，输入和输出指定为一系列符号。例如，翻译训练示例可以被写为序列（翻译成法语，英语文本，法语文本）。同样，阅读理解训练示例可以写为（回答问题，文档，问题，答案）。 McCann等。 （2018）演示了可以训练单个模型MQAN

以此类格式推断示例并执行许多不同的任务。语言建模原则上也能够学习McCann等人的任务。 （2018年），而无需明确监督要预测哪些符号。由于受监管的目标与无监管的目标相同，但仅在序列的子集上进行评估，因此无监管的目标的全局最小值也为有监管的目标的全局最小值。在这种略带玩具的环境中，避开了将密度估计作为（Sutskever等人，2015）中讨论的原则性训练目标的担忧。相反，问题在于我们是否能够在实践中优化不受监督的目标以实现收敛。初步实验证实，足够大的语言模型可以在这种玩具般的设置中执行多任务学习，但是与明显监督的方法相比，学习速度要慢得多。尽管从上述适当的设置到“野外语言”的混乱是迈出的一大步，但韦斯顿（2016年）在对话的背景下认为，需要开发能够直接从自然语言中学习的系统并演示了概念证明–通过使用教师输出的前瞻预测来学习没有奖励信号的QA任务。尽管对话是一种有吸引力的方法，但我们担心它过于严格。互联网包含大量信息，这些信息可以被动地获得，而无需交互通信。我们的推测是，具有足够能力的语言模型将开始学习推断和执行以自然语言顺序演示的任务，以便更好地预测它们，而不管其采购方式如何。如果语言模型能够做到这一点，则实际上将执行无监督的多任务学习。我们通过分析零任务设置下语言模型的性能来测试是否存在这种情况

先前的大多数工作都是在单个文本域上训练语言模型，例如新闻文章（Jozefowicz等人，2016），维基百科（Merity等人，2016）或小说书（Kiros等人，2015）。 我们的方法鼓励建立尽可能多的大型数据集，以便在尽可能多的域和上下文中收集任务的自然语言演示。 Web剪贴簿（例如Common Crawl）是多种多样且几乎无限文本的一个有希望的来源。 尽管这些档案比当前的语言建模数据集大许多数量级，但它们仍存在重大的数据质量问题。 Trinh＆Le（2018）在常识推理的工作中使用了Common Crawl，但注意到大量文档“其内容大多难以理解”。 在最初的实验中，我们观察到类似的数据问题常见的抓取。 Trinh＆Le（2018）的最佳结果是通过一个小型的Common Crawl子样本获得的，该子样本仅包含与目标数据集最相似的文档Winograd Schema Challenge。 虽然这是一种提高特定任务性能的实用方法，但我们希望避免对要提前执行的任务做出假设

取而代之的是，我们创建了一个新的Web抓取工具，强调文档质量。为此，我们只抓取经过人类策划/过滤的网页。手动过滤完整的Web抓取将非常昂贵，因此，作为一个起点，我们从社交媒体平台Reddit抓取了所有出站链接，该平台至少获得了3业力。可以将其视为其他用户是否发现链接有趣，有教育意义或仅仅是有趣的启发式指示器。所得的数据集WebText包含这4500万个链接的文本子集。为了从HTML响应中提取文本，我们使用了Dragnet（Peters和Lecocq，2013）和Newspaper1content提取器的组合。本文介绍的所有结果均使用WebText的初步版本，该版本不包括2017年12月之后创建的链接，该链接在重复数据删除和基于启发式的清理后包含略超过800万份文档，总计40 GB文本。我们从WebText中删除了所有Wikipedia文档，因为它是其他数据集的通用数据源，并且由于过度使用而使分析复杂化将培训数据与测试评估任务相结合

通用语言模型（LM）应该能够计算（并生成）任何字符串的概率。当前的大型LM包括预处理步骤，例如小写字母，标记化和语音不足标记，这些限制了可建模字符串的空间。在将Unicode字符串作为UTF-8字节序列处理时，优雅地满足了这一要求，如Gillick等人的工作中所例证的。 （2015年），当前的字节级LM在十亿字基准（Al-Rfou等人，2018年）等大型数据集上与字级LM不具有竞争力。我们在WebText上训练标准字节级LM的尝试中观察到了类似的性能差距。字节对编码（BPE）（Sennrich et al。，2015）是字符和单词级语言建模之间的实际中间地带，可以有效地在频繁的符号序列的单词级输入和不频繁的符号序列的字符级输入之间进行插值。尽管其名称，参考BPE实现通常在Unicode代码点而不是字节序列上运行。这些实现将需要包括Unicode符号的全部空间，以便对所有Unicode字符串建模。在添加任何多符号标记之前，这将导致基本词汇量超过130,000。与BPE经常使用的32,000至64,000个令牌词汇表相比，这个数目太大了。相反，BPE的字节级版本仅需要大小为256的基本词汇表。但是，由于BPE使用基于贪婪频率的启发式方法来构建令牌词汇表，因此直接将BPE应用于字节序列会导致次优合并。我们观察到BPE包含许多常见单词（如dog）的版本，因为它们以多种形式出现，例如dog。狗！狗？ 。这导致有限的词汇空位和模型容量的次优分配。为避免这种情况，我们防止BPE跨字符类别合并任何字节序列。我们为空格添加了一个例外，它极大地提高了压缩效率，同时在多个vocab标记之间仅添加了最小的单词碎片

这种输入表示形式使我们能够将字级LM的经验优势与字节级方法的一般性结合起来。 由于我们的方法可以将概率分配给任何Unicode字符串，因此我们可以在任何数据集上评估LM，而无需进行预处理，标记化处理或vocab大小

我们为LM使用基于Transformer（Vaswani等人，2017）的架构。 该模型在很大程度上遵循了OpenAI GPT模型（Radford等人，2018）的细节，

很少的修改。 将层归一化（Ba et al。，2016）移到每个子块的输入，类似于激活前的残差网络（He et al。，2016），并在最终自我关注之后添加了额外的层归一化 块。 使用修改后的初始化，该初始化考虑了具有模型深度的剩余路径上的累积。 我们在初始化时将残层的权重按1 /√N的比例进行缩放，其中N是残层的数量。 词汇扩展到50,257。 我们还将上下文大小从512个令牌增加到1024个令牌，并使用更大的512个批处理大小

我们以大约对数均匀间隔的尺寸训练和基准测试了四个LM。 表2总结了这些架构。最小的模型等效于原始GPT，第二最小的模型等效于BERT中的最大模型（Devlin等人，2018）。 我们最大的模型称为GPT-2，其参数比GPT大了一个数量级。 手动调整每个模型的学习率，以在5％的WebText样本中获得最佳的困惑。 所有模型仍然不适合Web文本，并且由于需要更多的培训时间，因此仍无法解决困惑问题

作为零任务转移的第一步，我们有兴趣了解WebText LM在零任务域转移中如何对其进行训练的主要任务-语言建模如何执行。 由于我们的模型在字节级别上运行，并且不需要有损的预处理或标记化，因此我们可以在任何语言模型基准上对其进行评估。 语言建模数据集上的结果通常以一定数量报告，该数量是每个规范预测单位（通常是字符，字节或单词）的平均负对数概率的成比例或加倍形式。 我们通过根据WebText LM计算数据集的对数概率并除以规范单位数来评估相同数量。 对于这些数据集中的许多数据集，WebText LM都将经过大量测试，而且必须预测积极标准化的文本，标记化伪像（例如标点符号和缩略词不连贯，乱序的句子，甚至是字符串）<UNK>这在WebText极为罕见 - 40个十亿字节存在的只有26倍。 我们在表3中报告了我们的主要结果，这些结果使用了可逆的去令牌器，该令牌可以尽可能多地消除这些令牌化/预处理工件。 由于这些去令牌器是可逆的，因此我们仍然可以计算数据集的对数概率，并且可以将它们视为域自适应的简单形式。 使用这些去令牌器，我们发现GPT-2的困惑度提高了2.5到5

WebText LM可以在域和数据集之间很好地传输，从而在零镜头设置下改善了8个数据集中的7个的最新技术水平。 在小型数据集（例如Penn Treebank和WikiText-2）上发现了很大的改进，它们只有1到2百万个训练令牌。 在为测量长期依赖性而创建的数据集（如LAMBADA（Paperno等，2016）和儿童图书测验（Hill等，2015））上也注意到了很大的改进。 我们的模型仍然比先前关于十亿字基准的研究差很多（Chelba等，2013）。 这可能是因为它既是最大的数据集，又具有某些最具破坏性的预处理功能的结合-1BW的句子级改组删除了所有远程结构

创建了儿童读物测试（CBT）（Hill等，2015），以检查LM在不同单词类别（命名实体，名词，动词和介词）上的性能。 CBT并没有将困惑性作为评估标准来报告，而是报告了自动构建的完形填空测试的准确性，该测试旨在预测被遗漏单词的10个可能选择中的哪一个是正确的。遵循原始论文中介绍的LM方法，我们根据LM计算每个选择的概率以及基于该选择的句子的其余部分，并预测概率最高的那个。如图2所示，随着模型尺寸的增加，性能稳步提高，并弥合了该测试中与人类性能的大部分差距。数据重叠分析显示，其中一本CBT测试集书籍《 Rudyard Kipling的The Jungle Book》在WebText中，因此我们在验证集中报告了没有明显重叠的结果。 GPT-2达到了最新的最新水平，普通名词占93.3％，命名实体占89.1％。应用了去令牌器从CBT中删除PTB样式的令牌化工件

LAMBADA数据集（Paperno等人，2016）测试了系统对文本中的远程依存关系建模的能力。任务是预测句子的最终词，该词需要至少50个上下文标记才能使人成功预测。 GPT-2将现有技术的复杂度从99.8（Grave等人，2016）提高到8.6，并将此测试中LM的准确性从19％（Dehghani等人，2018）提高到52.66％。调查GPT-2的错误表明，大多数预测是句子的有效延续，但不是有效的最终词。这表明LM没有使用附加的有用约束，即单词必须是句子的结尾。添加一个停用词过滤器作为对此的近似值，可以将准确度进一步提高到63.24％，从而使这项任务的最新技术水平提高了4％。之前的最新技术水平（Hoang等人，2018）使用了不同的受限预测设置，其中模型的输出仅限于出现在上下文中的单词。对于GPT-2，此限制有害无益因为19％的答案不在上下文中。 我们使用未经预处理的数据集版本

Winograd Schema挑战（Levesque等人，2012）旨在通过测量系统解决文本歧义的能力来衡量系统执行常识推理的能力。 最近，Trinh＆Le（2018）通过以更高的概率预测歧义的解决方案，证明了使用LM应对这一挑战的重大进展。 我们遵循他们的问题表述，并使用图3中的全部和部分评分技术来可视化模型的性能。GPT-2将最先进的准确性提高了7％，达到70.70％。 该数据集很小，只有273个示例，因此我们建议阅读Trichelair等。 （2018）帮助将这个结果与背景联系起来

会话问答数据库（CoQA）Reddy等。 （2018）包含来自7个不同领域的文档，以及关于该文档的提问者和问答者之间的自然语言对话。 CoQA测试阅读理解能力以及模型回答取决于对话历史记录的问题的能力（例如“为什么？”）。 根据文档，相关对话的历史记录和最终令牌A：以GPT-2为基础的贪婪解码，可在开发集上达到55 F1。 这与4个基准系统中的3个相匹配，甚至超过了它们的性能，而无需使用对这些基准进行训练的127,000+个手动收集的问题答案对。 受监督的SOTA，基于BERT的系统（Devlin等，2018），接近人类的89 F1表现。 尽管GPT-2的性能对于未经任何培训的系统来说是令人兴奋的，但是对它的答案和错误的一些检查表明，GPT-2经常使用基于简单检索的启发式方法，例如从文档中回答带有谁名字的答案

我们测试了GPT-2对CNN和Daily Mail数据集进行汇总的能力（Nallapati等，2016）。为了进行汇总行为，我们在文章后添加文本TL; DR :,并使用Top-k随机抽样（Fan等人，2018）生成100个令牌，k = 2，这减少了重复并鼓励了比贪婪解码。我们使用这100个令牌中的前3个生成的句子作为摘要。如表14所示，虽然从质量上讲，各代人看起来像摘要，但他们通常专注于文章的最新内容，或混淆具体细节，例如撞车涉及多少辆汽车或徽标是否戴在帽子或衬衫上。在通常报告的ROUGE 1,2，L度量标准上，生成的摘要仅开始接近经典神经基线的性能，并且仅差于从文章中选择3个随机句子的性能。删除任务提示后，GPT-2的性能在综合指标上下降了6.4点，这表明可以在具有自然语言的语言模型中调用特定于任务的行为

我们测试了GPT-2是否已经开始学习如何将一种语言翻译成另一种语言。 为了帮助我们推断这是一项理想的任务，我们以英语句子=法语句子格式的示例对为背景对语言模型进行条件调整，然后在英语句子=的最终提示后，我们从模型中采样 贪婪解码，并使用第一个生成的句子作为翻译。 在WMT-14英法测试集上，GPT-2的得分为5 BLEU，这比先前在无监督单词翻译中引入的双语词典逐词替换的效果稍差

Conneau et al。，2017b）。 在WMT-14法语-英语测试仪上，GPT-2能够利用其非常强大的英语模型来显着提高性能，达到11.5 BLEU。 这优于（Artetxe等人，2017）和（Lample等人，2017）的几个无监督机器翻译基准，但仍然比目前最好的无监督机器翻译方法（Artetxe等人，2019）的33.5 BLEU差得多。 。 由于我们有意从WebText中删除了非英语网页作为过滤步骤，因此该任务的性能令人惊讶。 为了确保这一点，我们在WebText上运行了字节级语言检测器2，该语言检测器仅检测10 MB的法语数据，比以前的无监督机器翻译研究中常见的单语种法语语料库小500倍。

测试语言模型中包含哪些信息的一种潜在方法是评估该信息多长时间生成一次针对类事实问题的正确答案。 先前在所有信息都存储在诸如神经对话模型（Vinyals＆Le，2015）之类的参数中的神经系统中，这种行为的展示报告了定性结果，原因是缺乏高质量的评估数据集。 最近引入的自然问题数据集（Kwiatkowski等

2019）是一个有希望的资源，可以对其进行更定量的测试。类似于翻译，语言模型的上下文中带有示例问题答案对，这有助于模型推断数据集的简短答案样式。当通过阅读理解数据集（如SQUAD）中常用的精确匹配度量标准进行评估时，GPT-2正确回答了4.1％的问题。3作为比较点，最小的模型的准确度不超过简单基线的1.0％。返回每种问题类型（谁，什么，在哪里等）的最常见答案。 GPT-2正确回答了5.3倍的问题，这表明到目前为止，模型能力一直是神经系统在此类任务上表现不佳的主要因素。 GPT-2为其生成的答案分配的概率已得到很好的校准，GPT-2在最自信的1％的问题上的准确度为63.1％。GPT-2在开发集上生成的30个最自信的答案问题显示在表5中.GPT-2的性能仍然比开放域问答系统的30％至50％范围要差很多，开放域问答系统将信息检索与提取文档问答相结合（Alberti等人，2019

计算机视觉的最新研究表明，普通图像数据集包含大量的近重复图像。 例如，CIFAR-10在训练图像和测试图像之间有3.3％的重叠（Barz＆Denzler，2019）。 这导致对机器学习系统的泛化性能的过度报告。 随着数据集大小的增加，此问题变得越来越可能，这表明WebText可能会发生类似现象。 因此，分析训练数据中还显示多少测试数据很重要。 为了对此进行研究，我们创建了包含8克WebText训练集标记的Bloom过滤器。 为了提高召回率，将字符串标准化为仅包含小写字母数字单词，并使用单个空格作为定界符。 Bloom滤波器的构造使误报率上限为1108。我们通过生成1M字符串进一步验证了低误报率，其中该字符串为零。

这些布隆过滤器使我们可以在给定数据集的情况下，从该数据集中计算8克的百分比，这些百分比也在WebText训练集中找到。 表6显示了通用LM基准测试集的这种重叠分析。 常见的LM数据集的测试集与Web-Text火车的重叠在1-6％之间，平均重叠为3.2％。 出乎意料的是，许多数据集与自己的训练拆分有较大的重叠，平均重叠率为5.9％。 我们的方法针对召回进行了优化，尽管手动检查重叠显示了许多常用短语，但是由于重复的数据，有许多较长的匹配项。 这不是WebText特有的。 例如，我们发现WikiText-103的测试集有一篇文章也位于训练数据集中。 由于测试集中只有60篇文章，因此至少有1.6％的重叠.4更令人担忧的是，根据我们的程序，1BW与自己的训练集的重叠接近13.2％

对于Winograd模式挑战，我们发现只有10个模式与WebText训练集有任何8克重叠。 其中，有2次是伪造的比赛。 在其余的8个方案中，只有1个方案出现在

对于CoQA而言，新闻领域中约15％的文档已经在WebText中，并且该模型在这些方面的性能更好约3 F1。 CoQA的开发设置指标报告了5个不同域的平均性能，由于各个域之间的重叠，我们测得的收益约为0.5-1.0 F1。但是，自从WebText链接的截止日期之后发布CoQA以来，WebText中没有实际的培训问题或答案。在LAMBADA上，平均重叠率为1.2％。在重叠率大于15％的示例中，GPT-2的混淆度提高了约2。当排除所有具有任何重叠移位的示例时，重新计算指标会导致8.6到8.7的困惑，并将准确性从63.2％降低到62.9％。总体结果中很小的变化很可能是由于200个示例中只有1个具有明显的重叠。总体而言，我们的分析表明，WebText训练数据与特定评估数据集之间的数据重叠为报告的结果提供了一个小而一致的好处。但是，对于大多数数据集，我们发现没有比标准训练和测试集之间已经存在的重叠大得多的重叠，如表6所示。了解和量化相似文本对性能的影响程度是一个重要的研究问题。更好的重复数据删除技术，例如可伸缩的模糊匹配，也可以帮助更好地回答这些问题。目前，我们建议在创建新的NLP数据集的训练和测试拆分期间，将基于n-gram重叠的重复数据删除用作重要的验证步骤和健全性检查。确定WebText LM的性能是否可归因于记忆的另一种可能方法是，根据自己的保留集检查其性能。如图4所示，WebText训练集和测试集的性能相似，并且随着模型大小的增加而一起提高。这表明，即使GPT-2仍然在很多方面都不适用于WebText。 GPT-2还能够撰写有关发现独角兽的新闻。表13提供了一个示例

这项工作的很大一部分衡量了在较大数据集上训练的较大语言模型的性能。 这个与Jozefowicz等人的工作相似。 （2016）在10亿单词基准测试中扩展了基于RNN的语言模型。 Bajgar等。 （2016）之前还通过在古腾堡计划中创建了更大的训练数据集来补充标准训练数据集，从而改善了儿童读物测试的结果。 Hestness等。 （2017）对各种深度学习模型的性能如何随模型容量和数据集大小的变化进行了彻底的分析。我们的实验虽然在各个任务之间会产生较大的噪音，但表明类似的趋势适用于目标的子任务，并继续进入1B +参数范围。之前已经记录了生成模型中有趣的学习功能，例如RNN语言模型中的单元执行线宽跟踪和引用/注释检测Karpathy等。 （2015）。 Liu等人的观察对我们的工作更具启发性。 （2018），一个经过训练可以生成Wikipedia文章的模型还学会了在语言之间翻译名称。先前的工作探索了替代方法来过滤和构建网页的大型文本语料库，例如iWeb语料库（Davies，2018年）。关于语言任务的预训练方法已经进行了广泛的工作。除了导言中提到的内容外，GloVe（Pennington等人，2014）将单词向量表示学习的规模扩展到了所有Common Crawl。关于文本的深度表示学习的一项有影响力的早期工作是“跳思想向量”（Kiros等人，2015）。 McCann等。 （2017）探索了从机器翻译模型和Howard＆Ruder（2018

改进了基于RNN的微调方法（Dai＆Le，2015）。 （Conneau等人，2017a）研究了通过自然语言推理模型学习的表示的传递性能，（Subramanian等人，2018）探索了大规模的多任务训练。 （Ramachandran等人，2016）证明了seq2seq模型受益于使用预训练的语言模型作为编码器和解码器进行初始化。 最近的工作表明，LM微调对于微妙地完成诸如聊天对话和基于对话的问答系统这样的难以完成的任务时很有帮助（Wolf等人，2019）（Dinan等人，2018）

许多研究致力于学习（Hill等人，2016），理解（Levy＆Goldberg，2014）以及严格评估（Wieting＆Kiela，2019）两种有监督和无监督预训练方法的表示。我们的结果表明，无监督任务学习是另外一个有希望的研究领域。这些发现可能有助于解释用于下游NLP任务的预训练技术的广泛成功，因为我们表明，在一定程度上，这些预训练技术之一开始学习直接执行任务，而无需进行有监督的适应或修改。 。在阅读理解上，GPT-2的性能与零击设置下的监督基准竞争。但是，在其他任务（例如摘要）上，虽然它是定性执行任务，但根据定量指标，其性能仍然只是基本的。虽然作为研究结果具有启发性，但就实际应用而言，GPT-2的零射性能仍远远不能使用。我们已经研究了WebText LM在许多规范的NLP任务上的零射性能，但是还可以评估许多其他任务。毫无疑问，在许多实际任务中，GPT-2的性能仍然不比随机性好。即使在我们评估过的常见任务（例如问题解答和翻译）上，语言模型也只有在具有足够能力的情况下才开始超越琐碎的基准

尽管零射性能为GPT-2在许多任务上的潜在性能奠定了基线，但尚不清楚微调的最高限度在哪里。 在某些任务上，GPT-2的完全抽象输出明显不同于基于提取指针网络（Vinyals等，2015）的输出，而基于提取指针网络的输出目前在许多问题解答和阅读理解数据集上都是最新的。 鉴于之前在GPT上进行微调的成功，我们计划在decaNLP和GLUE等基准测试上进行微调，尤其是因为目前尚不清楚

训练数据和GPT-2的能力足以克服BERT证明的单向表示效率低下的问题（Devlin等人，2018

在足够大且多样化的数据集上训练大型语言模型时，它能够在许多域和数据集上表现良好。 GPT-2在8个经过测试的语言建模数据集中有7个实现了最新性能的零射。 该模型能够在零镜头设置下执行的任务的多样性表明，经过训练以使文本语料库充分变化的可能性最大化的高容量模型开始学习如何执行数量惊人的任务，而无需明确的监督


感谢所有编写文本，共享链接和评论WebText中内容的人。 数百万人参与了GPT-2训练数据的创建。 还要感谢所有为我们提供培训基础设施帮助的Google员工，包括Zak Stone，JS Riehl，Jonathan Hseu，Russell Power，Youlong Cheng，Noam Shazeer，Solomon Boulos，Michael Banfield，Aman Gupta，Daniel Sohn等。 最后，感谢对本文草稿提供反馈的人员：雅各布·斯坦哈特，山姆·鲍曼，杰弗里·欧文和麦迪逊·梅